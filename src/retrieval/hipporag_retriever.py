# src/retrieval/hipporag_retriever.py
"""
HippoRAG Knowledge Graph Retriever
Sá»­ dá»¥ng HippoRAG API Ä‘á»ƒ retrieve documents vá»›i knowledge graph
Customized cho Vietnamese Traffic Law
"""

import os
import sys
from typing import List, Dict, Any
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun
from langchain.schema import Document
from pydantic import Field
import re

# Add HippoRAG directory to path
hipporag_path = os.path.join(os.path.dirname(__file__), '..', '..', 'HippoRAG', 'src')
if hipporag_path not in sys.path:
    sys.path.insert(0, hipporag_path)

from hipporag import HippoRAG
from hipporag.utils.config_utils import BaseConfig
from config import settings
from src.retrieval.vietnamese_law_prompts import get_vietnamese_law_prompts

# Mapping cÃ¡c vÄƒn báº£n cÃ³ lá»—i font encoding
DOCUMENT_MAPPING = {
    "Ngh nh 168-2024-N-CP": "Nghá»‹ Ä‘á»‹nh 168/2024/NÄ-CP",
    "Ngh nh 03-2021-N-CP": "Nghá»‹ Ä‘á»‹nh 03/2021/NÄ-CP", 
    "Ngh nh 100-2019-N-CP": "Nghá»‹ Ä‘á»‹nh 100/2019/NÄ-CP",
    "Ngh nh 123-2021-N-CP": "Nghá»‹ Ä‘á»‹nh 123/2021/NÄ-CP",
    "Lu t 35-2024-QH15": "Luáº­t 35/2024/QH15",
    "Lu t 36-2024-QH15": "Luáº­t 36/2024/QH15",
}

def _override_hipporag_prompts():
    """
    Override HippoRAG default prompts vá»›i Vietnamese Traffic Law prompts
    PHáº¢I Gá»ŒI TRÆ¯á»šC khi khá»Ÿi táº¡o HippoRAG (nhÆ° trong notebook section 5)
    """
    try:
        # Import prompt templates tá»« HippoRAG
        from hipporag.prompts.templates import ner, triple_extraction, rag_qa_musique
        
        # Get Vietnamese law prompts
        vn_prompts = get_vietnamese_law_prompts()
        
        # Override NER prompt (giá»‘ng y há»‡t notebook)
        ner.ner_system = vn_prompts['ner']['system']
        ner.one_shot_ner_paragraph = vn_prompts['ner']['example_input']
        ner.one_shot_ner_output = vn_prompts['ner']['example_output']
        ner.prompt_template = vn_prompts['ner']['prompt_template']
        
        # Override Triple Extraction prompt
        triple_extraction.ner_conditioned_re_system = vn_prompts['triple_extraction']['system']
        triple_extraction.ner_conditioned_re_output = vn_prompts['triple_extraction']['example_output']
        
        # Override QA prompt
        rag_qa_musique.rag_qa_system = vn_prompts['qa']['system']
        
        print("âœ… Prompts overridden successfully:")
        print("   - NER: Vietnamese Traffic Law specific")
        print("   - Triple extraction: Optimized for law relationships")
        print("   - QA: Legal citation enforced")
        
    except Exception as e:
        print(f"âš ï¸ Warning: Could not override prompts: {e}")
        print("   Using default HippoRAG prompts instead")


class HippoRAGRetriever(BaseRetriever):
    """
    HippoRAG-based retriever sá»­ dá»¥ng knowledge graph
    Customized cho Vietnamese Traffic Law vá»›i:
    - Custom NER prompts cho entities trong luáº­t giao thÃ´ng
    - Custom Triple Extraction cho relationships trong Ä‘iá»u khoáº£n
    - Custom QA prompts vá»›i citation enforcement
    
    Flow (giá»‘ng y há»‡t notebook):
    1. Override prompts TRÆ¯á»šC khi init HippoRAG
    2. Initialize HippoRAG vá»›i custom config
    3. Use hipporag.retrieve() Ä‘á»ƒ retrieve documents
    4. Format thÃ nh LangChain Documents
    """
    
    hipporag: Any = Field(default=None, description="HippoRAG instance")
    max_docs_per_query: int = Field(default=3, description="Max documents per query")
    
    def __init__(self, max_docs_per_query: int = 3, **kwargs):
        """Initialize HippoRAG retriever vá»›i Vietnamese Traffic Law customization"""
        
        # Load OpenAI API key tá»« settings hoáº·c environment
        openai_api_key = getattr(settings, 'OPENAI_API_KEY', None) or os.getenv('OPENAI_API_KEY')
        
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in settings or environment variables")
        
        os.environ["OPENAI_API_KEY"] = openai_api_key
        
        # âš ï¸ QUAN TRá»ŒNG: Override prompts TRÆ¯á»šC KHI táº¡o config (nhÆ° notebook)
        print("ðŸ“ Overriding prompts with Vietnamese Traffic Law templates...")
        _override_hipporag_prompts()
        
        # Debug: Print path being used
        print(f"ðŸ“ HIPPORAG_SAVE_DIR: {settings.HIPPORAG_SAVE_DIR}")
        print(f"   Path exists: {os.path.exists(settings.HIPPORAG_SAVE_DIR)}")
        if os.path.exists(settings.HIPPORAG_SAVE_DIR):
            print(f"   Contents: {os.listdir(settings.HIPPORAG_SAVE_DIR)}")
        
        # Create custom config cho Vietnamese Traffic Law (tá»« notebook section 3)
        print("âš™ï¸ Creating custom HippoRAG config for Vietnamese Traffic Law...")
        config = BaseConfig(
            # LLM config
            llm_name=settings.HIPPORAG_LLM_NAME,
            max_new_tokens=settings.HIPPORAG_MAX_NEW_TOKENS,
            temperature=settings.HIPPORAG_TEMPERATURE,

            # Embedding config - Vietnamese model
            embedding_model_name=settings.HIPPORAG_EMBEDDING_MODEL,
            embedding_batch_size=settings.HIPPORAG_EMBEDDING_BATCH_SIZE,
            embedding_return_as_normalized=settings.HIPPORAG_EMBEDDING_RETURN_NORMALIZED,
            embedding_max_seq_len=settings.HIPPORAG_EMBEDDING_MAX_SEQ_LEN,

            # Preprocessing config
            preprocess_chunk_max_token_size=settings.HIPPORAG_CHUNK_MAX_TOKEN_SIZE,
            preprocess_chunk_overlap_token_size=settings.HIPPORAG_CHUNK_OVERLAP_TOKEN_SIZE,
            preprocess_chunk_func=settings.HIPPORAG_CHUNK_FUNC,

            # Graph construction config
            synonymy_edge_topk=settings.HIPPORAG_SYNONYMY_EDGE_TOPK,
            synonymy_edge_sim_threshold=settings.HIPPORAG_SYNONYMY_EDGE_SIM_THRESHOLD,
            is_directed_graph=settings.HIPPORAG_IS_DIRECTED_GRAPH,

            # Retrieval config
            linking_top_k=settings.HIPPORAG_LINKING_TOP_K,
            retrieval_top_k=settings.HIPPORAG_RETRIEVAL_TOP_K,
            passage_node_weight=settings.HIPPORAG_PASSAGE_NODE_WEIGHT,
            damping=settings.HIPPORAG_DAMPING,

            # QA config
            max_qa_steps=settings.HIPPORAG_MAX_QA_STEPS,
            qa_top_k=settings.HIPPORAG_QA_TOP_K,

            # Storage config - dÃ¹ng save_dir tá»« settings
            save_dir=settings.HIPPORAG_SAVE_DIR,
            save_openie=settings.HIPPORAG_SAVE_OPENIE,
            force_index_from_scratch=settings.HIPPORAG_FORCE_INDEX_FROM_SCRATCH,
        )
        
        print("âœ… Custom config created:")
        print(f"   - LLM: {config.llm_name}")
        print(f"   - Embedding: {config.embedding_model_name}")
        print(f"   - Save dir: {config.save_dir}")
        print(f"   - Chunk size: {config.preprocess_chunk_max_token_size} tokens")
        print(f"   - Retrieval top-k: {config.retrieval_top_k}")
        
        # Initialize HippoRAG vá»›i custom config
        print("ðŸ§  Initializing HippoRAG Knowledge Graph...")
        hipporag_instance = HippoRAG(
            global_config=config,
            save_dir=settings.HIPPORAG_SAVE_DIR,
            llm_model_name=config.llm_name,
            embedding_model_name=config.embedding_model_name
        )

        if hasattr(hipporag_instance, 'graph') and hipporag_instance.graph is not None:
            print("Knowledge Graph Statistics:")
            print(f"  - Total nodes: {hipporag_instance.graph.vcount()}")
            print(f"  - Total edges: {hipporag_instance.graph.ecount()}")
            print(f"  - Average degree: {2 * hipporag_instance.graph.ecount() / hipporag_instance.graph.vcount():.2f}")
            # Kiá»ƒm tra má»™t sá»‘ node máº«u
            if hipporag_instance.graph.vcount() > 0:
                print("\nSample nodes:")
                for i in range(min(5, hipporag_instance.graph.vcount())):
                    node_name = hipporag_instance.graph.vs[i]['name'] if 'name' in hipporag_instance.graph.vs.attributes() else f"Node {i}"
                    print(f"  - {node_name}")
        else:
            print("Graph not yet initialized. Run indexing first.")
        
        super().__init__(
            hipporag=hipporag_instance,
            max_docs_per_query=max_docs_per_query,
            **kwargs
        )
        
        print("âœ… HippoRAG Retriever initialized successfully with Vietnamese Law customization")
    
    def _get_relevant_documents(
        self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """Required method from BaseRetriever"""
        return self._hipporag_search(query)
    
    def _hipporag_search(self, query: str) -> List[Document]:
        """
        Sá»­ dá»¥ng HippoRAG Ä‘á»ƒ search vá»›i knowledge graph
        
        Returns:
            List[Document]: Documents vá»›i enhanced citations
        """
        try:
            print(f"ðŸ§  HippoRAG searching for: {query}")
            
            # Call HippoRAG API
            queries = [query]
            rag_results = self.hipporag.rag_qa(queries=queries)
            
            if not rag_results or not rag_results[0]:
                print("âš ï¸ No results from HippoRAG")
                return []
            
            documents = []
            query_solution = rag_results[0][0]  # First query's first solution
            
            # Extract answer
            answer = query_solution.answer
            
            # Process each document trong results
            for doc_idx, doc_text in enumerate(query_solution.docs[:self.max_docs_per_query]):
                # Parse citation tá»« document title
                citation_info = self._parse_citation(doc_text)
                
                # Create metadata
                metadata = {
                    "_source": "hipporag",
                    "_query": query,
                    "_answer": answer,
                    "legal_citation": citation_info["formatted_citation"],
                    "law_id": citation_info["law_id"],
                    "article_id": citation_info["article_id"],
                    "clause_id": citation_info.get("clause_id"),
                    "has_legal_citation": True,
                    "_retrieval_method": "hipporag_knowledge_graph"
                }
                
                # Clean document content (remove citation header)
                clean_content = self._clean_document(doc_text)
                
                # Create Document
                doc = Document(
                    page_content=clean_content,
                    metadata=metadata
                )
                documents.append(doc)
                
                print(f"ðŸ“„ HippoRAG Doc {doc_idx+1}: {citation_info['formatted_citation']}")
            
            print(f"âœ… HippoRAG retrieved {len(documents)} documents")
            return documents
            
        except Exception as e:
            print(f"âŒ HippoRAG search failed: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def _parse_citation(self, doc_text: str) -> Dict[str, Any]:
        """
        Parse citation tá»« document text
        
        Format: [Nghá»‹ Ä‘á»‹nh 168-2024-NÄ-CP] Äiá»u 32 Má»¥c 16
        """
        citation_info = {
            "law_id": None,
            "article_id": None,
            "clause_id": None,
            "formatted_citation": "KhÃ´ng xÃ¡c Ä‘á»‹nh nguá»“n"
        }
        
        try:
            # Extract title line (first line)
            lines = doc_text.split('\n')
            if not lines:
                return citation_info
            
            title_line = lines[0].strip()
            
            # Parse law ID tá»« brackets [...]
            law_match = re.search(r'\[(.*?)\]', title_line)
            if law_match:
                law_id_raw = law_match.group(1)
                # Fix encoding issues
                law_id = DOCUMENT_MAPPING.get(law_id_raw, law_id_raw)
                citation_info["law_id"] = law_id
            
            # Parse article (Äiá»u X)
            article_match = re.search(r'Äiá»u\s+(\d+)', title_line)
            if article_match:
                citation_info["article_id"] = article_match.group(1)
            
            # Parse clause (Má»¥c/Khoáº£n X)
            clause_match = re.search(r'(?:Má»¥c|Khoáº£n)\s+(\d+)', title_line)
            if clause_match:
                citation_info["clause_id"] = clause_match.group(1)
            
            # Build formatted citation
            parts = []
            if citation_info["law_id"]:
                parts.append(citation_info["law_id"])
            if citation_info["article_id"]:
                parts.append(f"Äiá»u {citation_info['article_id']}")
            if citation_info["clause_id"]:
                parts.append(f"Khoáº£n {citation_info['clause_id']}")
            
            if parts:
                citation_info["formatted_citation"] = ", ".join(parts)
            
        except Exception as e:
            print(f"âš ï¸ Citation parsing failed: {e}")
        
        return citation_info
    
    def _clean_document(self, doc_text: str) -> str:
        """Remove citation header vÃ  clean document"""
        lines = doc_text.split('\n')
        
        # Remove first line (citation header)
        if lines and re.match(r'\[.*?\]', lines[0]):
            lines = lines[1:]
        
        # Join and clean
        cleaned = '\n'.join(lines).strip()
        return cleaned


def get_hipporag_retriever(max_docs_per_query: int = 3) -> HippoRAGRetriever:
    """
    Factory function Ä‘á»ƒ táº¡o HippoRAG retriever
    
    Args:
        max_docs_per_query: Sá»‘ documents tá»‘i Ä‘a cho má»—i query
    
    Returns:
        HippoRAGRetriever instance
    """
    return HippoRAGRetriever(max_docs_per_query=max_docs_per_query)
